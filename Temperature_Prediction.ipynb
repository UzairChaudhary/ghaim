{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4963aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name:Aisha Amenhali\n",
    "#Date:6-4-2025\n",
    "# Section 1- Weather Predication model and Data Analysis for temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ab295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import load_iris \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe85ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 -> import the csv file and delete that first column\n",
    "data = pd.read_csv(\"Dataset_temperature.csv\", encoding='cp1252')\n",
    "data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether the dataset is balanced or not\n",
    "weather_counts = data[\"Weather Category\"].value_counts()\n",
    "temp_data = pd.DataFrame({\n",
    "    \"weather condition\":weather_counts.index,\n",
    "    \"Counts\":weather_counts.values\n",
    "})\n",
    "\n",
    "plt.figure(figsize = (18,8))\n",
    "sns.barplot(x=\"weather condition\", y=\"Counts\", data = temp_data)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 7', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d86cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset first few rows\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97719150",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ed461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Outliers: Check for outliers in numerical columns\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=data[[\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ecb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Outliers Using IQR Method\n",
    "Q1 = data[[\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\"]].quantile(0.25)\n",
    "Q3 = data[[\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\"]].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "\n",
    "low = Q1 - 1.5*IQR\n",
    "upper = Q3 + 1.5*IQR\n",
    "\n",
    "data_cleaned = data[~((data<low) | (data > upper)).any(axis=1)]\n",
    "\n",
    "print(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107bbaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify the Dataset After Outlier Removal\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=data_cleaned[[\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\",\"Weather Category\",\"Emirate\"]])\n",
    "plt.title(\"Box Plot After Outlier Removal\")\n",
    "print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf21022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip extreme instead extreme values it's not important to remove data\n",
    "data[[\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\"]] = data[[\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\"]].clip(low,upper,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9af61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot: to identify the relationship between two variables Temp_Min[°C] and Temp_Max[°C]\n",
    "plt.scatter(data[\"Temp_Max[?øC]\"],data[\"Temp_Min[?øC]\"])\n",
    "plt.title(\"Scatter Plot\")\n",
    "plt.xlabel(\"Temperature Maximum\")\n",
    "plt.ylabel(\"Temperature Minimum\")\n",
    "plt.colorbar()\n",
    "print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line Chart Two show the relationship between the weather condition and Temp_Mean[°C]\n",
    "plt.plot(data[\"Weather Category\"])\n",
    "plt.plot(data[\"Temp_Mean[?øC]\"])\n",
    "plt.title(\"Line Chart\")\n",
    "plt.xlabel('Weather condition')\n",
    "plt.ylabel(\"Average Temperature\")\n",
    "print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e18b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multivariate Analysis (Comapring Multiple Variables) a pairplot\n",
    "sns.pairplot(data[[\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for corretions among the features\n",
    "cols = [\"Year\",\"Month\",\"Day\",\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\",\"Weather Category\",\"Emirate\"]\n",
    "cor_matrix = data[cols].corr()\n",
    "cor_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9300a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(11,7))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='spring',linewidth=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8407a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the typo and ensuring correct usage\n",
    "plt.pie(data['Weather Category'].value_counts().values,  # Fix: value_counts() instead of values_counts()\n",
    "        labels=data['Weather Category'].value_counts().index,\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['lightblue', 'lightgreen', 'pink', 'red', 'purple'],  # Optional: Add colors\n",
    "        startangle=90,  # Rotate for better visibility\n",
    "        wedgeprops={'edgecolor': 'black'})  # Add borders for better clarity\n",
    "\n",
    "plt.title('Distribution of Weather Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83bf11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Weather Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4824fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Bulid the predictive model for weather prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['Weather Category'] = le.fit_transform(data['Weather Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35760331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['Emirate'] = le.fit_transform(data['Emirate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a MinMaxScaler instance for Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = data[[\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\"]]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled_d= pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(X_scaled_d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data for training and testing model\n",
    "#We split the dataset into 80% training and 20% testing:\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:, -1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"Y_train: {Y_train.shape}, Y_test: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf3d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data for training and testing model\n",
    "#We split the dataset into 80% training and 20% testing:\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:, -1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "print(f\"Train:{X_train.shape},{Y_train.shape}\")\n",
    "print(f\"Train:{X_test.shape},{Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c405f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the columns exist\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isnan(X_train).sum())  # Should be 0\n",
    "print(np.isinf(X_train).sum())  # Should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb2515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no data loss during splitting\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y if len(set(Y)) > 1 else None\n",
    ")\n",
    "\n",
    "print(X_train.shape)  # Should be non-zero\n",
    "print(Y_train.shape)  # Should be non-zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Sample X_train rows:\\n\", X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d91cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using K-Fold Cross-Validation for model Selection\n",
    "#Model Buliding\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply Label Encoding\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    \n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = le.fit_transform(y)  # Convert target variable to numbers\n",
    "\n",
    "print(X.dtypes)\n",
    "print(X.head())  # Check first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd4285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ebab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "X_selected = SelectKBest(f_classif, k=10).fit_transform(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc3517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using K-Fold Cross-Validation for model Selection\n",
    "#Model Buliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[[\"Year\",\"Month\",\"Day\",\"Temp_Max[?øC]\",\"Temp_Mean[?øC]\",\"Temp_Min[?øC]\",\"Emirate\"]]\n",
    "y=data[\"Weather Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc2420",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34562c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Model 1: SVC\n",
    "svc_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "svc_grid = GridSearchCV(SVC(), svc_params, cv=cv)\n",
    "svc_grid.fit(X_pca, y_resampled)\n",
    "svc_score = cross_val_score(svc_grid.best_estimator_, X_pca, y_resampled, cv=cv).mean()\n",
    "\n",
    "# Model 2: GaussianNB\n",
    "nb_model = GaussianNB()\n",
    "nb_score = cross_val_score(nb_model, X_pca, y_resampled, cv=cv).mean()\n",
    "\n",
    "# Model 3: Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=cv)\n",
    "rf_grid.fit(X_pca, y_resampled)\n",
    "rf_score = cross_val_score(rf_grid.best_estimator_, X_pca, y_resampled, cv=cv).mean()\n",
    "\n",
    "# Print all results\n",
    "print(\"============================================================\")\n",
    "print(\"Best SVC Score:\", svc_score)\n",
    "print(\"Best GaussianNB Score:\", nb_score)\n",
    "print(\"Best Random Forest Score:\", rf_score)\n",
    "print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056be9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=18)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233009be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predication\n",
    "y_pred_R=rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix \n",
    "# The accuracy for our model\n",
    "accuracy_score(Y_test,y_pred_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"Temp_Max[?øC]\",\"Temp_Min[?øC]\",\"Temp_Mean[?øC]\"]] \n",
    "y = data['Weather Category'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "preds = svm_model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on train data by SVM Classifier: {accuracy_score(y_train, svm_model.predict(X_train)) * 100}\")\n",
    "print(f\"Accuracy on test data by SVM Classifier: {accuracy_score(y_test, preds) * 100}\")\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "plt.title(\"Confusion Matrix for SVM Classifier on Test Data\")\n",
    "plt.show()\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "preds = nb_model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on train data by Naive Bayes Classifier: {accuracy_score(y_train, nb_model.predict(X_train)) * 100}\")\n",
    "print(f\"Accuracy on test data by Naive Bayes Classifier: {accuracy_score(y_test, preds) * 100}\")\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "plt.title(\"Confusion Matrix for Naive Bayes Classifier on Test Data\")\n",
    "plt.show()\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=18)\n",
    "rf_model.fit(X_train, y_train)\n",
    "preds = rf_model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on train data by Random Forest Classifier: {accuracy_score(y_train, rf_model.predict(X_train)) * 100}\")\n",
    "print(f\"Accuracy on test data by Random Forest Classifier: {accuracy_score(y_test, preds) * 100}\")\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "plt.title(\"Confusion Matrix for Random Forest Classifier on Test Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(rf_model, X_train, Y_train, cv=10, n_jobs=-1)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Score:\", np.mean(cv_scores))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e546fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
